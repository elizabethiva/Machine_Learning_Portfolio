{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elizabethiva/Machine_Learning_Portfolio/blob/main/Sunspot_Activity_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh4wl6ZdJysU"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/main/C4/W4/ungraded_labs/C4_W4_Lab_3_Sunspots_CNN_RNN_DNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywktc8UkWbRv"
      },
      "source": [
        "# Predicting Sunspots with Neural Networks\n",
        "\n",
        "This project focuses on measuring and forecasting sunspot activity. Sunspots, dark areas on the sun's surface, are a crucial aspect of solar research and have implications for space weather and terrestrial communications.\n",
        "\n",
        "The goal of this project is to analyze and predict sunspot activity based on historical data.\n",
        "The analysis is based on historical data from the [Sunspots Dataset](https://www.kaggle.com/datasets/robervalt/sunspots), spanning 272 years (1749-2021) of monthly sunspot counts.\n",
        "The model leverages convolutional layers followed by stacked LSTMs and dense layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR3s1iNXW8qv"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLl52leVp5wU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import requests"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the Dataset"
      ],
      "metadata": {
        "id": "XqE3UBBTjxXR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miE0cEqdu3eS"
      },
      "outputs": [],
      "source": [
        "# Get Sunspots Dataset\n",
        "url = 'https://raw.githubusercontent.com/elizabethiva/Machine_Learning_Portfolio/main/data/Sunspots.csv'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the content of the CSV file\n",
        "response = requests.get(url)\n",
        "csv_content = response.text\n",
        "\n",
        "# Split the content into lines\n",
        "csv_lines = csv_content.split('\\n')\n",
        "\n",
        "# Path to the file where the dataset will be saved\n",
        "sunspots = 'sunspots.csv'\n",
        "\n",
        "# Save the dataset to a CSV file\n",
        "with open(sunspots, 'w') as csv_file:\n",
        "    csv_file.write(csv_content)"
      ],
      "metadata": {
        "id": "T_n7nKL6IuQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTgnwTJiW-bF"
      },
      "source": [
        "The `plot_series` function visualizes time series data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDrgVqCTao9j"
      },
      "outputs": [],
      "source": [
        "def plot_series(x, y, format=\"-\", start=0, end=None,\n",
        "                title=None, xlabel=None, ylabel=None, legend=None ):\n",
        "    \"\"\"\n",
        "    Visualizes time series data\n",
        "\n",
        "    Args:\n",
        "      x (array of int) - contains values for the x-axis\n",
        "      y (array of int or tuple of arrays) - contains the values for the y-axis\n",
        "      format (string) - line style when plotting the graph\n",
        "      start (int) - first time step to plot\n",
        "      end (int) - last time step to plot\n",
        "      title (string) - title of the plot\n",
        "      xlabel (string) - label for the x-axis\n",
        "      ylabel (string) - label for the y-axis\n",
        "      legend (list of strings) - legend for the plot\n",
        "    \"\"\"\n",
        "\n",
        "    # Setup dimensions of the graph figure\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Check if there are more than two series to plot\n",
        "    if type(y) is tuple:\n",
        "\n",
        "      # Loop over the y elements\n",
        "      for y_curr in y:\n",
        "\n",
        "        # Plot the x and current y values\n",
        "        plt.plot(x[start:end], y_curr[start:end], format)\n",
        "\n",
        "    else:\n",
        "      # Plot the x and y values\n",
        "      plt.plot(x[start:end], y[start:end], format)\n",
        "\n",
        "    # Label the x-axis\n",
        "    plt.xlabel(xlabel)\n",
        "\n",
        "    # Label the y-axis\n",
        "    plt.ylabel(ylabel)\n",
        "\n",
        "    # Set the legend\n",
        "    if legend:\n",
        "      plt.legend(legend)\n",
        "\n",
        "    # Set the title\n",
        "    plt.title(title)\n",
        "\n",
        "    # Overlay a grid on the graph\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Draw the graph on screen\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU9FU6-BXE56"
      },
      "source": [
        "## Pre-processing and Preview the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcG9r1eClbTh"
      },
      "outputs": [],
      "source": [
        "# Initialize lists\n",
        "time_step = []\n",
        "sunspots = []\n",
        "\n",
        "# Open CSV file\n",
        "with open('sunspots.csv') as csvfile:\n",
        "\n",
        "  # Initialize reader\n",
        "  reader = csv.reader(csvfile, delimiter=',')\n",
        "\n",
        "  # Skip the first line\n",
        "  next(reader)\n",
        "\n",
        "  # Append row and sunspot number to lists\n",
        "  for row in reader:\n",
        "    time_step.append(int(row[0]))\n",
        "    sunspots.append(float(row[2]))\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "time = np.array(time_step)\n",
        "series = np.array(sunspots)\n",
        "\n",
        "# Preview the data\n",
        "plot_series(time, series, xlabel='Month', ylabel='Monthly Mean Total Sunspot Number')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq34m86mXHk4"
      },
      "source": [
        "## Split the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L92YRw_IpCFG"
      },
      "outputs": [],
      "source": [
        "# Define the split time\n",
        "split_time = 3000\n",
        "\n",
        "# Get the train set\n",
        "time_train = time[:split_time]\n",
        "x_train = series[:split_time]\n",
        "\n",
        "# Get the validation set\n",
        "time_valid = time[split_time:]\n",
        "x_valid = series[split_time:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlJDtNMDXkJF"
      },
      "source": [
        "## Prepare Features and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJwUUZscnG38"
      },
      "outputs": [],
      "source": [
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    \"\"\"Generates dataset windows\n",
        "\n",
        "    Args:\n",
        "      series (array of float) - contains the values of the time series\n",
        "      window_size (int) - the number of time steps to include in the feature\n",
        "      batch_size (int) - the batch size\n",
        "      shuffle_buffer(int) - buffer size to use for the shuffle method\n",
        "\n",
        "    Returns:\n",
        "      dataset (TF Dataset) - TF Dataset containing time windows\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a TF Dataset from the series values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "    # Window the data but only take those with the specified size\n",
        "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Flatten the windows by putting its elements in a single batch\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "\n",
        "    # Create tuples with features and labels\n",
        "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "\n",
        "    # Shuffle the windows\n",
        "    dataset = dataset.shuffle(shuffle_buffer)\n",
        "\n",
        "    # Create batches of windows\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z0qRGp1zl5b"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "window_size = 30\n",
        "batch_size = 32\n",
        "shuffle_buffer_size = 1000\n",
        "\n",
        "# Generate the dataset windows\n",
        "train_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylQoAXTaXscV"
      },
      "source": [
        "## Build the Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6kJd40-0Hj9"
      },
      "outputs": [],
      "source": [
        "# Build the Model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv1D(filters=64, kernel_size=3,\n",
        "                      strides=1,\n",
        "                      activation=\"relu\",\n",
        "                      padding='causal',\n",
        "                      input_shape=[window_size, 1]),\n",
        "  tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "  tf.keras.layers.LSTM(64),\n",
        "  tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "])\n",
        "\n",
        " # Print the model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBYFogmdFM-R"
      },
      "outputs": [],
      "source": [
        "# Set the initial learning rate\n",
        "initial_learning_rate=1e-7\n",
        "\n",
        "# Define the scheduler\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=400,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True)\n",
        "\n",
        "# Set the optimizer\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9)\n",
        "\n",
        "# Set the training parameters\n",
        "model.compile(loss=tf.keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrcqLyLALmCY"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_set,epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAzIkJd0L6WD"
      },
      "source": [
        "The model architecture is designed to achieve a loss of 16.2 and a Mean Absolute Error (MAE) of 16.7 when predicting sunspot activity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD2kyYUVt3O0"
      },
      "outputs": [],
      "source": [
        "# Get mae and loss from history log\n",
        "mae=history.history['mae']\n",
        "loss=history.history['loss']\n",
        "\n",
        "# Get number of epochs\n",
        "epochs=range(len(loss))\n",
        "\n",
        "# Plot mae and loss\n",
        "plot_series(\n",
        "    x=epochs,\n",
        "    y=(mae, loss),\n",
        "    title='MAE and Loss',\n",
        "    xlabel='MAE',\n",
        "    ylabel='Loss',\n",
        "    legend=['MAE', 'Loss']\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHxos0eEX7b7"
      },
      "source": [
        "## Model Prediction\n",
        "\n",
        "Let's get the predictions for the validation set time range and compute the metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XwGrf-A_wF0"
      },
      "outputs": [],
      "source": [
        "def model_forecast(model, series, window_size, batch_size):\n",
        "    \"\"\"Uses an input model to generate predictions on data windows\n",
        "\n",
        "    Args:\n",
        "      model (TF Keras Model) - model that accepts data windows\n",
        "      series (array of float) - contains the values of the time series\n",
        "      window_size (int) - the number of time steps to include in the window\n",
        "      batch_size (int) - the batch size\n",
        "\n",
        "    Returns:\n",
        "      forecast (numpy array) - array containing predictions\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate a TF Dataset from the series values\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "\n",
        "    # Window the data but only take those with the specified size\n",
        "    dataset = dataset.window(window_size, shift=1, drop_remainder=True)\n",
        "\n",
        "    # Flatten the windows by putting its elements in a single batch\n",
        "    dataset = dataset.flat_map(lambda w: w.batch(window_size))\n",
        "\n",
        "    # Create batches of windows\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "\n",
        "    # Get predictions on the entire dataset\n",
        "    forecast = model.predict(dataset)\n",
        "\n",
        "    return forecast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5f7kKbFL6zv"
      },
      "outputs": [],
      "source": [
        "# Reduce the original series\n",
        "forecast_series = series[split_time-window_size:-1]\n",
        "\n",
        "# Use helper function to generate predictions\n",
        "forecast = model_forecast(model, forecast_series, window_size, batch_size)\n",
        "\n",
        "# Drop single dimensional axis\n",
        "results = forecast.squeeze()\n",
        "\n",
        "# Plot the results\n",
        "plot_series(time_valid, (x_valid, results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jZrRYjQMNHr"
      },
      "outputs": [],
      "source": [
        "# Compute the MAE\n",
        "print(tf.keras.metrics.mean_absolute_error(x_valid, results).numpy())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}